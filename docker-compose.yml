version: '3.7'

services:
    app:
        image: streamlit-python3.11:latest
        container_name: streamlit
        build:
            context: .
            dockerfile: Dockerfile
        command: streamlit run Home.py --server.port 18501
        volumes:
            - ./app:/usr/src/app
            - ./files:/tmp/files
        ports:
            - 18501:18501

    ollama:
        image: ollama/ollama:latest
        ports:
            - 27869:11434
        volumes:
            - ./ollama/code:/code
            - ./ollama/ollama:/root/.ollama
        container_name: ollama
        pull_policy: always
        tty: true
        restart: always
        environment:
            - OLLAMA_KEEP_ALIVE=24h
            - OLLAMA_HOST=0.0.0.0
        networks:
            - ollama-docker

    ollama-webui:
        image: ghcr.io/open-webui/open-webui:main
        container_name: ollama-webui
        volumes:
            - ./ollama/ollama-webui:/app/backend/data
        depends_on:
            - ollama
        ports:
            - 28080:8080
        environment: # https://docs.openwebui.com/getting-started/env-configuration#default_models
            - OLLAMA_BASE_URLS=http://host.docker.internal:27869 #comma separated ollama hosts
            - ENV=dev
            - WEBUI_AUTH=False
            - WEBUI_NAME=HYPER AI
            - WEBUI_URL=http://localhost:28080
            - WEBUI_SECRET_KEY=t0p-s3cr3t
            - OPENAI_API_KEY=temp-api-key
        extra_hosts:
            - host.docker.internal:host-gateway
        restart: unless-stopped
        networks:
            - ollama-docker

networks:
  ollama-docker:
    external: false